{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import model_preparation\n",
    "import keras as kr\n",
    "\n",
    "from model_preparation import prepare_data, get_features, get_bounds, get_interval_accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Load in pre-split data\n",
    "X_train, X_test, y_train, y_test = prepare_data()\n",
    "features = get_features()\n",
    "train_bounds_5 = get_bounds(y_train, 5)\n",
    "train_bounds_10 = get_bounds(y_train, 10)\n",
    "test_bounds_5 = get_bounds(y_test, 5)\n",
    "test_bounds_10 = get_bounds(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten target variable to use in NN models\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                530       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define functions for NN models, running models, etc\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim = 52, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal', activation = 'linear'))\n",
    "    adam = Adam()\n",
    "    # Compile\n",
    "    model.compile(loss = 'mean_squared_error', optimizer=adam, metrics =['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def run_network(xtrain, xtest, ytrain, ytest, model, epochs, batch):\n",
    "    model.fit(xtrain, ytrain, nb_epoch = epochs, batch_size = batch,\n",
    "              validation_data = (xtest, ytest),verbose = 2)\n",
    "    return model\n",
    "\n",
    "# Change the number of layers but hold the number of hidden neurons constant\n",
    "def change_layers_neurons(numlayers, numneurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(numneurons, input_dim = 52, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    for x in range(1- numlayers):\n",
    "        model.add(Dense(numneurons, kernel_initializer = 'normal', activation = 'relu'))\n",
    "    model.add(Dense(1, kernel_initializer = 'normal', activation = 'linear'))\n",
    "    adam = Adam()\n",
    "    model.compile(loss = 'mean_squared_error', optimizer=adam, metrics =['mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "basemodel = base_model()\n",
    "basemodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bicaj\\documents\\projects\\machine learning\\spanish-high-speed-rail-renfe\\venv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 610.6786 - mean_squared_error: 610.6790 - val_loss: 108.4281 - val_mean_squared_error: 108.4281\n",
      "Epoch 2/10\n",
      " - 4s - loss: 106.3870 - mean_squared_error: 106.3871 - val_loss: 103.6248 - val_mean_squared_error: 103.6248\n",
      "Epoch 3/10\n",
      " - 4s - loss: 103.4697 - mean_squared_error: 103.4697 - val_loss: 101.3156 - val_mean_squared_error: 101.3156\n",
      "Epoch 4/10\n",
      " - 4s - loss: 100.5074 - mean_squared_error: 100.5075 - val_loss: 98.2846 - val_mean_squared_error: 98.2845\n",
      "Epoch 5/10\n",
      " - 4s - loss: 97.6705 - mean_squared_error: 97.6705 - val_loss: 96.3182 - val_mean_squared_error: 96.3181\n",
      "Epoch 6/10\n",
      " - 4s - loss: 95.4899 - mean_squared_error: 95.4898 - val_loss: 94.6744 - val_mean_squared_error: 94.6744\n",
      "Epoch 7/10\n",
      " - 4s - loss: 93.9441 - mean_squared_error: 93.9442 - val_loss: 93.8857 - val_mean_squared_error: 93.8857\n",
      "Epoch 8/10\n",
      " - 4s - loss: 93.0375 - mean_squared_error: 93.0374 - val_loss: 93.4500 - val_mean_squared_error: 93.4500\n",
      "Epoch 9/10\n",
      " - 4s - loss: 92.3808 - mean_squared_error: 92.3806 - val_loss: 92.6608 - val_mean_squared_error: 92.6609\n",
      "Epoch 10/10\n",
      " - 4s - loss: 91.9880 - mean_squared_error: 91.9879 - val_loss: 93.8052 - val_mean_squared_error: 93.8052\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 687.9848 - mean_squared_error: 687.9847 - val_loss: 114.7213 - val_mean_squared_error: 114.7213\n",
      "Epoch 2/10\n",
      " - 4s - loss: 107.1882 - mean_squared_error: 107.1882 - val_loss: 102.1207 - val_mean_squared_error: 102.1207\n",
      "Epoch 3/10\n",
      " - 4s - loss: 101.4744 - mean_squared_error: 101.4744 - val_loss: 99.4130 - val_mean_squared_error: 99.4129\n",
      "Epoch 4/10\n",
      " - 4s - loss: 99.3363 - mean_squared_error: 99.3362 - val_loss: 98.6023 - val_mean_squared_error: 98.6023\n",
      "Epoch 5/10\n",
      " - 5s - loss: 98.0764 - mean_squared_error: 98.0766 - val_loss: 97.0516 - val_mean_squared_error: 97.0516\n",
      "Epoch 6/10\n",
      " - 4s - loss: 97.2700 - mean_squared_error: 97.2699 - val_loss: 96.9926 - val_mean_squared_error: 96.9926\n",
      "Epoch 7/10\n",
      " - 4s - loss: 96.7311 - mean_squared_error: 96.7310 - val_loss: 95.9499 - val_mean_squared_error: 95.9498\n",
      "Epoch 8/10\n",
      " - 4s - loss: 96.2939 - mean_squared_error: 96.2937 - val_loss: 95.7108 - val_mean_squared_error: 95.7107\n",
      "Epoch 9/10\n",
      " - 4s - loss: 95.8932 - mean_squared_error: 95.8932 - val_loss: 95.3132 - val_mean_squared_error: 95.3132\n",
      "Epoch 10/10\n",
      " - 4s - loss: 95.5758 - mean_squared_error: 95.5758 - val_loss: 95.1100 - val_mean_squared_error: 95.1100\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 25s - loss: 95.6700 - mean_squared_error: 95.6695 - val_loss: 94.4739 - val_mean_squared_error: 94.4741\n",
      "Epoch 2/10\n",
      " - 25s - loss: 95.1208 - mean_squared_error: 95.1208 - val_loss: 95.4791 - val_mean_squared_error: 95.4792\n",
      "Epoch 3/10\n",
      " - 29s - loss: 94.8882 - mean_squared_error: 94.8883 - val_loss: 94.0057 - val_mean_squared_error: 94.0057\n",
      "Epoch 4/10\n",
      " - 51s - loss: 94.7253 - mean_squared_error: 94.7255 - val_loss: 94.0198 - val_mean_squared_error: 94.0198\n",
      "Epoch 5/10\n",
      " - 42s - loss: 94.5321 - mean_squared_error: 94.5323 - val_loss: 95.4650 - val_mean_squared_error: 95.4650\n",
      "Epoch 6/10\n",
      " - 49s - loss: 94.4483 - mean_squared_error: 94.4480 - val_loss: 96.0019 - val_mean_squared_error: 96.0018\n",
      "Epoch 7/10\n",
      " - 45s - loss: 94.3694 - mean_squared_error: 94.3693 - val_loss: 93.5580 - val_mean_squared_error: 93.5580\n",
      "Epoch 8/10\n",
      " - 51s - loss: 94.3319 - mean_squared_error: 94.3316 - val_loss: 93.5944 - val_mean_squared_error: 93.5943\n",
      "Epoch 9/10\n",
      " - 52s - loss: 94.1197 - mean_squared_error: 94.1196 - val_loss: 93.7866 - val_mean_squared_error: 93.7865\n",
      "Epoch 10/10\n",
      " - 50s - loss: 94.1328 - mean_squared_error: 94.1323 - val_loss: 93.6477 - val_mean_squared_error: 93.6475\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 597.1235 - mean_squared_error: 597.1239 - val_loss: 111.3585 - val_mean_squared_error: 111.3584\n",
      "Epoch 2/10\n",
      " - 10s - loss: 107.9352 - mean_squared_error: 107.9353 - val_loss: 104.7926 - val_mean_squared_error: 104.7926\n",
      "Epoch 3/10\n",
      " - 8s - loss: 105.4083 - mean_squared_error: 105.4083 - val_loss: 104.1142 - val_mean_squared_error: 104.1142\n",
      "Epoch 4/10\n",
      " - 10s - loss: 104.9281 - mean_squared_error: 104.9282 - val_loss: 103.6889 - val_mean_squared_error: 103.6890\n",
      "Epoch 5/10\n",
      " - 11s - loss: 104.5362 - mean_squared_error: 104.5364 - val_loss: 103.4784 - val_mean_squared_error: 103.4784\n",
      "Epoch 6/10\n",
      " - 10s - loss: 104.4013 - mean_squared_error: 104.4013 - val_loss: 103.5148 - val_mean_squared_error: 103.5147\n",
      "Epoch 7/10\n",
      " - 9s - loss: 104.2861 - mean_squared_error: 104.2861 - val_loss: 103.4862 - val_mean_squared_error: 103.4862\n",
      "Epoch 8/10\n",
      " - 8s - loss: 104.2019 - mean_squared_error: 104.2019 - val_loss: 103.1900 - val_mean_squared_error: 103.1900\n",
      "Epoch 9/10\n",
      " - 10s - loss: 104.1375 - mean_squared_error: 104.1376 - val_loss: 103.6727 - val_mean_squared_error: 103.6726\n",
      "Epoch 10/10\n",
      " - 11s - loss: 104.0884 - mean_squared_error: 104.0883 - val_loss: 103.5364 - val_mean_squared_error: 103.5364\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 602.9148 - mean_squared_error: 602.9150 - val_loss: 112.4741 - val_mean_squared_error: 112.4741\n",
      "Epoch 2/10\n",
      " - 9s - loss: 107.9863 - mean_squared_error: 107.9864 - val_loss: 104.6808 - val_mean_squared_error: 104.6808\n",
      "Epoch 3/10\n",
      " - 10s - loss: 105.4557 - mean_squared_error: 105.4557 - val_loss: 105.2001 - val_mean_squared_error: 105.2002\n",
      "Epoch 4/10\n",
      " - 8s - loss: 104.8391 - mean_squared_error: 104.8391 - val_loss: 103.8098 - val_mean_squared_error: 103.8098\n",
      "Epoch 5/10\n",
      " - 9s - loss: 104.5639 - mean_squared_error: 104.5640 - val_loss: 103.4469 - val_mean_squared_error: 103.4470\n",
      "Epoch 6/10\n",
      " - 8s - loss: 104.4011 - mean_squared_error: 104.4010 - val_loss: 103.3443 - val_mean_squared_error: 103.3442\n",
      "Epoch 7/10\n",
      " - 11s - loss: 104.2693 - mean_squared_error: 104.2691 - val_loss: 103.4150 - val_mean_squared_error: 103.4150\n",
      "Epoch 8/10\n",
      " - 8s - loss: 104.1498 - mean_squared_error: 104.1498 - val_loss: 103.3790 - val_mean_squared_error: 103.3790\n",
      "Epoch 9/10\n",
      " - 8s - loss: 104.1222 - mean_squared_error: 104.1222 - val_loss: 103.0752 - val_mean_squared_error: 103.0752\n",
      "Epoch 10/10\n",
      " - 11s - loss: 104.0516 - mean_squared_error: 104.0516 - val_loss: 103.2093 - val_mean_squared_error: 103.2092\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 693.5323 - mean_squared_error: 693.5317 - val_loss: 112.4535 - val_mean_squared_error: 112.4535\n",
      "Epoch 2/10\n",
      " - 12s - loss: 108.1872 - mean_squared_error: 108.1872 - val_loss: 104.8511 - val_mean_squared_error: 104.8511\n",
      "Epoch 3/10\n",
      " - 9s - loss: 103.8245 - mean_squared_error: 103.8245 - val_loss: 100.7896 - val_mean_squared_error: 100.7895\n",
      "Epoch 4/10\n",
      " - 10s - loss: 100.0018 - mean_squared_error: 100.0018 - val_loss: 97.3854 - val_mean_squared_error: 97.3854\n",
      "Epoch 5/10\n",
      " - 11s - loss: 96.7926 - mean_squared_error: 96.7925 - val_loss: 95.3737 - val_mean_squared_error: 95.3737\n",
      "Epoch 6/10\n",
      " - 11s - loss: 94.6903 - mean_squared_error: 94.6903 - val_loss: 93.4192 - val_mean_squared_error: 93.4191\n",
      "Epoch 7/10\n",
      " - 10s - loss: 93.2010 - mean_squared_error: 93.2010 - val_loss: 92.5129 - val_mean_squared_error: 92.5128\n",
      "Epoch 8/10\n",
      " - 11s - loss: 92.2508 - mean_squared_error: 92.2508 - val_loss: 91.9449 - val_mean_squared_error: 91.9448\n",
      "Epoch 9/10\n",
      " - 9s - loss: 91.6480 - mean_squared_error: 91.6479 - val_loss: 91.3082 - val_mean_squared_error: 91.3082\n",
      "Epoch 10/10\n",
      " - 8s - loss: 91.3006 - mean_squared_error: 91.3007 - val_loss: 90.9552 - val_mean_squared_error: 90.9552\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 503.9229 - mean_squared_error: 503.9224 - val_loss: 107.3568 - val_mean_squared_error: 107.3568\n",
      "Epoch 2/10\n",
      " - 11s - loss: 103.3276 - mean_squared_error: 103.3277 - val_loss: 97.7966 - val_mean_squared_error: 97.7966\n",
      "Epoch 3/10\n",
      " - 12s - loss: 95.8555 - mean_squared_error: 95.8557 - val_loss: 93.6245 - val_mean_squared_error: 93.6245\n",
      "Epoch 4/10\n",
      " - 11s - loss: 92.6900 - mean_squared_error: 92.6897 - val_loss: 91.6173 - val_mean_squared_error: 91.6171\n",
      "Epoch 5/10\n",
      " - 9s - loss: 91.3341 - mean_squared_error: 91.3342 - val_loss: 90.9774 - val_mean_squared_error: 90.9774\n",
      "Epoch 6/10\n",
      " - 8s - loss: 90.4840 - mean_squared_error: 90.4841 - val_loss: 89.5727 - val_mean_squared_error: 89.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      " - 11s - loss: 88.2518 - mean_squared_error: 88.2518 - val_loss: 88.0503 - val_mean_squared_error: 88.0502\n",
      "Epoch 8/10\n",
      " - 11s - loss: 86.4969 - mean_squared_error: 86.4969 - val_loss: 86.4009 - val_mean_squared_error: 86.4008\n",
      "Epoch 9/10\n",
      " - 9s - loss: 85.5985 - mean_squared_error: 85.5985 - val_loss: 87.3551 - val_mean_squared_error: 87.3551\n",
      "Epoch 10/10\n",
      " - 8s - loss: 84.9916 - mean_squared_error: 84.9916 - val_loss: 85.7345 - val_mean_squared_error: 85.7345\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 465.8546 - mean_squared_error: 465.8544 - val_loss: 105.1633 - val_mean_squared_error: 105.1633\n",
      "Epoch 2/10\n",
      " - 9s - loss: 101.5680 - mean_squared_error: 101.5680 - val_loss: 96.8866 - val_mean_squared_error: 96.8865\n",
      "Epoch 3/10\n",
      " - 11s - loss: 93.9801 - mean_squared_error: 93.9803 - val_loss: 91.1072 - val_mean_squared_error: 91.1072\n",
      "Epoch 4/10\n",
      " - 10s - loss: 89.2637 - mean_squared_error: 89.2636 - val_loss: 88.4595 - val_mean_squared_error: 88.4595\n",
      "Epoch 5/10\n",
      " - 11s - loss: 86.5295 - mean_squared_error: 86.5294 - val_loss: 86.3063 - val_mean_squared_error: 86.3063\n",
      "Epoch 6/10\n",
      " - 9s - loss: 84.9033 - mean_squared_error: 84.9032 - val_loss: 85.5926 - val_mean_squared_error: 85.5927\n",
      "Epoch 7/10\n",
      " - 10s - loss: 83.9828 - mean_squared_error: 83.9829 - val_loss: 84.2629 - val_mean_squared_error: 84.2629\n",
      "Epoch 8/10\n",
      " - 9s - loss: 83.0729 - mean_squared_error: 83.0730 - val_loss: 83.8758 - val_mean_squared_error: 83.8758\n",
      "Epoch 9/10\n",
      " - 11s - loss: 82.3164 - mean_squared_error: 82.3165 - val_loss: 83.1640 - val_mean_squared_error: 83.1640\n",
      "Epoch 10/10\n",
      " - 8s - loss: 81.7120 - mean_squared_error: 81.7120 - val_loss: 82.8960 - val_mean_squared_error: 82.8960\n",
      "Train on 80000 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 398.1707 - mean_squared_error: 398.1705 - val_loss: 104.0845 - val_mean_squared_error: 104.0844\n",
      "Epoch 2/10\n",
      " - 12s - loss: 99.7505 - mean_squared_error: 99.7506 - val_loss: 94.0833 - val_mean_squared_error: 94.0833\n",
      "Epoch 3/10\n",
      " - 13s - loss: 91.1129 - mean_squared_error: 91.1129 - val_loss: 89.1754 - val_mean_squared_error: 89.1753\n",
      "Epoch 4/10\n",
      " - 11s - loss: 86.4401 - mean_squared_error: 86.4403 - val_loss: 85.2555 - val_mean_squared_error: 85.2555\n",
      "Epoch 5/10\n",
      " - 10s - loss: 83.7554 - mean_squared_error: 83.7554 - val_loss: 83.1864 - val_mean_squared_error: 83.1864\n",
      "Epoch 6/10\n",
      " - 12s - loss: 81.7645 - mean_squared_error: 81.7644 - val_loss: 81.8180 - val_mean_squared_error: 81.8179\n",
      "Epoch 7/10\n",
      " - 12s - loss: 79.9898 - mean_squared_error: 79.9895 - val_loss: 80.1336 - val_mean_squared_error: 80.1335\n",
      "Epoch 8/10\n",
      " - 13s - loss: 78.6900 - mean_squared_error: 78.6900 - val_loss: 78.7222 - val_mean_squared_error: 78.7222\n",
      "Epoch 9/10\n",
      " - 13s - loss: 77.7908 - mean_squared_error: 77.7907 - val_loss: 78.2596 - val_mean_squared_error: 78.2596\n",
      "Epoch 10/10\n",
      " - 11s - loss: 77.0482 - mean_squared_error: 77.0483 - val_loss: 77.3667 - val_mean_squared_error: 77.3667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1e4a42a2908>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run Network for Base Model\n",
    "run_network(X_train, X_test, y_train, y_test, basemodel, 10,20)\n",
    "\n",
    "# Create more networks hold number of neurons/layer constant\n",
    " \n",
    "# 5 layers\n",
    "model1 = change_layers_neurons(5, 10)\n",
    "run_network(X_train, X_test, y_train, y_test, model1, 10,20)\n",
    "run_network(X_train, X_test, y_train, y_test, model1, 10,3)\n",
    "\n",
    "# 10 layers\n",
    "model2 = change_layers_neurons(10, 10)\n",
    "run_network(X_train, X_test, y_train, y_test, model2, 10,20)\n",
    "\n",
    "# 15 layers\n",
    "model3 = change_layers_neurons(15, 10)\n",
    "run_network(X_train, X_test, y_train, y_test, model3, 10,20)\n",
    "\n",
    "# 25 layers\n",
    "model4 = change_layers_neurons(25, 10)\n",
    "run_network(X_train, X_test, y_train, y_test, model4, 10,20)\n",
    "\n",
    "\n",
    "# Create layers with more neurons, hold number of layers constant\n",
    "\n",
    "# 15 neurons\n",
    "model5 = change_layers_neurons(3, 15)\n",
    "run_network(X_train, X_test, y_train, y_test, model5, 10,20)\n",
    "\n",
    "# 20 neurons\n",
    "model6 = change_layers_neurons(3, 20)\n",
    "run_network(X_train, X_test, y_train, y_test, model6, 10,20)\n",
    "\n",
    "# 30 neurons\n",
    "model7 = change_layers_neurons(3, 30)\n",
    "run_network(X_train, X_test, y_train, y_test, model7, 10,20)\n",
    "\n",
    "## Model 7 performs the best with lowest MSE on testing and will be used for model predictions and evaluation below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8819338723093375\n",
      "77.36669890027484\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions using best model training on neural network (model 7)\n",
    "y_pred_train_nn = model7.predict(X_train)\n",
    "y_pred_test_nn = model7.predict(X_test)\n",
    "\n",
    "# Compute R2 and MSE on test data\n",
    "print(r2_score(y_test, y_pred_test_nn))\n",
    "print(mean_squared_error(y_test, y_pred_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% +/- limit:\n",
      "0.3686\n",
      "10% +/- limit:\n",
      "0.6065\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy scores for 5% and 10% intervals on test data\n",
    "print(\"5% +/- limit:\")\n",
    "print(np.mean(get_interval_accuracy_score(test_bounds_5, y_pred_test_nn)))\n",
    "print(\"10% +/- limit:\")\n",
    "print(np.mean(get_interval_accuracy_score(test_bounds_10, y_pred_test_nn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
